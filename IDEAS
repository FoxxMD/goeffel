## Data collection

- Use eBPF for acquiring advanced kernel statistics:
    - https://pypi.org/project/pyebpf/
    - https://github.com/iovisor/bcc


## Data emission

- allow for emitting data into a metrics pipeline via network (statsd, ...)


## File management

- File management in general: prevent accidental concurrent write access.
  Example scenario: goeffel started twice with default args in the same second.
  File locking?


## goeffel-analysis

- For the magic plot allow for a non-interactive mode which only writes to disk.

- control log level with command line flag

- make non-interactive mode default because of the figure size issue:
  https://github.com/matplotlib/matplotlib/issues/7338
  Write PDF and PNG by default.


## Ideas for walk-through / tutorial / blog:

- Show how PID command picks up new PID
- Show inspect
- Show magic
- Show non-interactive magic, writing PNG file


## Misc notes

- Add a 'label' concept, an arbitrary label that would be stored with the HDF5
  meta data, and would also automatically be appended to
    - the default HDF5 file name
    - the figure file names generated by the analysis program

- goeffel cmdline args: make first argument positional arg, and auto-detect
  whether it's an integer (PID) or otherwise PID command (cleaner semantics)

- build a mode without process-specific monitoring (no pid, no pid command)?

- measure resource utilization of goeffel with another instance of goeffel.

- Replace HDF5 type for columns with unit 'percent' to be Float16 instead of Float32?

- architecture: if the sample writer crashes for whichever reason we want to
  crash the entire program, right?

- Allow for installing `goefel` w/o the depdencies required solely for
  `goeffel-analysis`.

- Add option to not measure IP connections? Can be CPU costly. Measure/compare.
  Does this matter?

- Noticed during development: using `stress` and `pgrep gnome-shell` is nice
  and all, but maybe: add a test process functionality into Goeffel itself so
  that playing with it on the command line is easy?

- On a loaded system profile goeffel and see where it spends its time.
  Pops up in top with 6 % CPU utilization. A quick `perf top` on the
  sampling process shows that it spends most of its time in kernel space,
  not too bad:

    Overhead  Shared Object         Symbol
      14.90%  [kernel]              [k] vsnprintf
      14.87%  [kernel]              [k] established_get_first.isra.40
      11.22%  [kernel]              [k] format_decode
       6.13%  [kernel]              [k] number.isra.2
       3.98%  [kernel]              [k] __memcpy


## Precision of sampling interval

This shows the systematic error of sleeping for a constant time (instead of
using a deadline-based approach) pretty well:

  In [7]: df['unixtime'].diff().mean()
  Out[7]: 1.0908292996759117

Here, Goeffel was started using a sampling interval of 1.0 seconds.

With two conceptual optimizations this is now much better (a large number of
samples, 0.5 s sampling interval):

- mean: 0.5003 s
- max:  0.5014 s
- min:  0.4989 s
- std:  0.0004 s

btw, done with pandas like this:

pd.read_hdf('./goeffel_timeseries__20190806_205617.hdf5', key="goeffel_timeseries")['unixtime'].diff().max()
